{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dae26240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, max, min, asc, desc, current_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType, DateType, DoubleType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "add0cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"spark-s3-delta\")\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \",\".join([\n",
    "            \"io.delta:delta-spark_2.12:3.1.0\",\n",
    "            \"org.apache.hadoop:hadoop-aws:3.3.4\",\n",
    "            \"com.amazonaws:aws-java-sdk-bundle:1.12.262\"\n",
    "        ])\n",
    "    )\n",
    "    .config(\n",
    "        \"spark.sql.extensions\",\n",
    "        \"io.delta.sql.DeltaSparkSessionExtension\"\n",
    "    )\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "hadoop_conf = spark._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "hadoop_conf.set(\n",
    "    \"fs.s3a.aws.credentials.provider\",\n",
    "    \"com.amazonaws.auth.DefaultAWSCredentialsProviderChain\"\n",
    ")\n",
    "\n",
    "hadoop_conf.set(\"fs.s3a.path.style.access\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "139dbd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema definition\n",
    "\n",
    "region_schema = StructType([\n",
    "    StructField('cities', ArrayType(StringType()), nullable = True),\n",
    "    StructField('iso', StringType(), nullable = True),\n",
    "    StructField('lat', StringType(), nullable = True),\n",
    "    StructField('long', StringType(), nullable = True),\n",
    "    StructField('name', StringType(), nullable = True),\n",
    "    StructField('province', StringType(), nullable = True)\n",
    "])\n",
    "\n",
    "raw_schema = StructType([\n",
    "    StructField('active', IntegerType(), nullable = True),\n",
    "    StructField('active_diff', IntegerType(), nullable = True),\n",
    "    StructField('confirmed', IntegerType(), nullable = True),\n",
    "    StructField('confirmed_diff', IntegerType(), nullable = True),\n",
    "    StructField('date', DateType(), nullable = True),\n",
    "    StructField('deaths', IntegerType(), nullable = True),\n",
    "    StructField('deaths_diff', IntegerType(), nullable = True),\n",
    "    StructField('fatality_rate', DoubleType(), nullable = True),\n",
    "    StructField('last_update', TimestampType(), nullable = True),\n",
    "    StructField('recovered', IntegerType(), nullable = True),\n",
    "    StructField('recovered_diff', IntegerType(), nullable = True),\n",
    "    StructField('region', region_schema, nullable = True),\n",
    "    StructField('ingested_ts', TimestampType(), nullable = False),\n",
    "    StructField('source_file_index', StringType(), nullable = False)\n",
    "])\n",
    "\n",
    "target_schema = StructType([\n",
    "    StructField('active', IntegerType(), nullable = True),\n",
    "    StructField('active_diff', IntegerType(), nullable = True),\n",
    "    StructField('confirmed', IntegerType(), nullable = True),\n",
    "    StructField('confirmed_diff', IntegerType(), nullable = True),\n",
    "    StructField('date', DateType(), nullable = True),\n",
    "    StructField('deaths', IntegerType(), nullable = True),\n",
    "    StructField('deaths_diff', IntegerType(), nullable = True),\n",
    "    StructField('fatality_rate', DoubleType(), nullable = True),\n",
    "    StructField('last_update', TimestampType(), nullable = True),\n",
    "    StructField('recovered', IntegerType(), nullable = True),\n",
    "    StructField('recovered_diff', IntegerType(), nullable = True),\n",
    "    StructField('cities', ArrayType(StringType()), nullable = True),\n",
    "    StructField('iso', StringType(), nullable = True),\n",
    "    StructField('lat', DoubleType(), nullable = True),\n",
    "    StructField('long', DoubleType(), nullable = True),\n",
    "    StructField('name', StringType(), nullable = True),\n",
    "    StructField('province', StringType(), nullable = True),\n",
    "    StructField('ingested_ts', TimestampType(), nullable = False),\n",
    "    StructField('source_file_index', StringType(), nullable = False),\n",
    "    StructField('created_ts', TimestampType(), nullable=False),\n",
    "    StructField('updated_ts', TimestampType(), nullable=False)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d0846fa5-cc07-40b8-8b32-4249d733fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_aws_path = 's3a://vd-airflow-docker-bucket/covid/Canada/raw'\n",
    "\n",
    "curated_aws_path = 's3a://vd-airflow-docker-bucket/covid/Canada/curated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b65010f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load as DF for Pyspark Operations (select, filter, agg, etc.)\n",
    "raw_df = spark.read.schema(raw_schema).json(raw_aws_path)\n",
    "curated_df = spark.read.format('delta').load(curated_aws_path)\n",
    "\n",
    "# Load as DeltaTable - This will be used as the target for Delta Table Operations (Merge/Upsert)\n",
    "curated_target_table = DeltaTable.forPath(spark, curated_aws_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "922751bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = curated_df.select('date').agg(max('date')).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1820fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening raw data. Region --> cities, iso, lat, long, name, province\n",
    "\n",
    "df_flattened = (\n",
    "                raw_df                                               \\\n",
    "                .select(\n",
    "                col('active').alias('active'),\n",
    "                col('active_diff').alias('active_diff'),\n",
    "                col('confirmed').alias('confirmed'),\n",
    "                col('confirmed_diff').alias('confirmed_diff'),\n",
    "                col('date').alias('date'),\n",
    "                col('deaths').alias('deaths'),\n",
    "                col('deaths_diff').alias('deaths_diff'),\n",
    "                col('fatality_rate').alias('fatality_rate'),\n",
    "                col('last_update').alias('last_update'),\n",
    "                col('recovered').alias('recovered'),\n",
    "                col('recovered_diff').alias('recovered_diff'),\n",
    "                col('region.cities').alias('cities'), \n",
    "                col('region.iso').alias('iso'),              # Cast to correct type\n",
    "                col('region.lat').alias('lat').cast('double'), \n",
    "                col('region.long').alias('long').cast('double'), \n",
    "                col('region.name').alias('name'), \n",
    "                col('region.province').alias('province'),\n",
    "                col('ingested_ts').alias('ingested_ts'),\n",
    "                col('source_file_index').alias('source_file_index')\n",
    "                )\n",
    "                # Add metadata timestamp\n",
    "                .withColumn('created_ts', current_timestamp())         \n",
    "                .withColumn('updated_ts', current_timestamp()) \n",
    "                # Set date for full load\n",
    "                .filter(col('date')>= date)                             \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8d081630-db84-4d65-90bb-987bb2b74a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to Insert: {'active': Column<'source.active'>, 'active_diff': Column<'source.active_diff'>, 'confirmed': Column<'source.confirmed'>, 'confirmed_diff': Column<'source.confirmed_diff'>, 'date': Column<'source.date'>, 'deaths': Column<'source.deaths'>, 'deaths_diff': Column<'source.deaths_diff'>, 'fatality_rate': Column<'source.fatality_rate'>, 'last_update': Column<'source.last_update'>, 'recovered': Column<'source.recovered'>, 'recovered_diff': Column<'source.recovered_diff'>, 'cities': Column<'source.cities'>, 'iso': Column<'source.iso'>, 'lat': Column<'source.lat'>, 'long': Column<'source.long'>, 'name': Column<'source.name'>, 'province': Column<'source.province'>, 'ingested_ts': Column<'source.ingested_ts'>, 'source_file_index': Column<'source.source_file_index'>, 'created_ts': Column<'source.created_ts'>, 'updated_ts': Column<'source.updated_ts'>}\n",
      "Columns to Update: {'active': Column<'source.active'>, 'active_diff': Column<'source.active_diff'>, 'confirmed': Column<'source.confirmed'>, 'confirmed_diff': Column<'source.confirmed_diff'>, 'date': Column<'source.date'>, 'deaths': Column<'source.deaths'>, 'deaths_diff': Column<'source.deaths_diff'>, 'fatality_rate': Column<'source.fatality_rate'>, 'last_update': Column<'source.last_update'>, 'recovered': Column<'source.recovered'>, 'recovered_diff': Column<'source.recovered_diff'>, 'cities': Column<'source.cities'>, 'iso': Column<'source.iso'>, 'lat': Column<'source.lat'>, 'long': Column<'source.long'>, 'name': Column<'source.name'>, 'province': Column<'source.province'>, 'ingested_ts': Column<'source.ingested_ts'>, 'source_file_index': Column<'source.source_file_index'>, 'updated_ts': Column<'source.updated_ts'>}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, max, min, asc, desc\n",
    "\n",
    "# Full Schema Dict for Insert (whenNotMatchedInsert)\n",
    "schema_dict = {}\n",
    "# Schema Dict without created ts (whenMatchedUpdate)\n",
    "schema_dict_update = {}\n",
    "\n",
    "for field_name in target_schema.fieldNames():\n",
    "    schema_dict[field_name] = col(f'source.{field_name}')\n",
    "    if field_name not in ['created_ts']:\n",
    "        schema_dict_update[field_name] = col(f'source.{field_name}')\n",
    "print(f'Columns to Insert: {schema_dict}')\n",
    "\n",
    "print(f'Columns to Update: {schema_dict_update}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c9080fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- active: integer (nullable = true)\n",
      " |-- active_diff: integer (nullable = true)\n",
      " |-- confirmed: integer (nullable = true)\n",
      " |-- confirmed_diff: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- deaths: integer (nullable = true)\n",
      " |-- deaths_diff: integer (nullable = true)\n",
      " |-- fatality_rate: double (nullable = true)\n",
      " |-- last_update: timestamp (nullable = true)\n",
      " |-- recovered: integer (nullable = true)\n",
      " |-- recovered_diff: integer (nullable = true)\n",
      " |-- cities: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- iso: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- ingested_ts: timestamp (nullable = true)\n",
      " |-- source_file_index: string (nullable = true)\n",
      " |-- created_ts: timestamp (nullable = false)\n",
      " |-- updated_ts: timestamp (nullable = false)\n",
      "\n",
      "root\n",
      " |-- active: integer (nullable = true)\n",
      " |-- active_diff: integer (nullable = true)\n",
      " |-- confirmed: integer (nullable = true)\n",
      " |-- confirmed_diff: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- deaths: integer (nullable = true)\n",
      " |-- deaths_diff: integer (nullable = true)\n",
      " |-- fatality_rate: double (nullable = true)\n",
      " |-- last_update: timestamp (nullable = true)\n",
      " |-- recovered: integer (nullable = true)\n",
      " |-- recovered_diff: integer (nullable = true)\n",
      " |-- cities: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- iso: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- ingested_ts: timestamp (nullable = true)\n",
      " |-- source_file_index: string (nullable = true)\n",
      " |-- created_ts: timestamp (nullable = true)\n",
      " |-- updated_ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flattened.printSchema()\n",
    "curated_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe2269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append to existing table\n",
    "# df_flattened.write.format('delta').mode('append').save(curated_aws_path)\n",
    "\n",
    "# Merge upsert to existing table\n",
    "curated_target_table.alias('target').merge(\n",
    "    df_flattened.alias('source'),\n",
    "    'target.source_file_index = source.source_file_index AND target.date = source.date AND target.province = source.province'\n",
    ") \\\n",
    ".whenMatchedUpdate(set=schema_dict_update) \\\n",
    ".whenNotMatchedInsert(values=schema_dict) \\\n",
    ".execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "93448242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------+--------------+----------+------+-----------+-------------+-------------------+---------+--------------+------+---+-------+---------+------+----------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|active|active_diff|confirmed|confirmed_diff|      date|deaths|deaths_diff|fatality_rate|        last_update|recovered|recovered_diff|cities|iso|    lat|     long|  name|        province|        ingested_ts|   source_file_index|          created_ts|          updated_ts|\n",
      "+------+-----------+---------+--------------+----------+------+-----------+-------------+-------------------+---------+--------------+------+---+-------+---------+------+----------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|     2|          0|        2|             0|2020-01-31|     0|          0|          0.0|2020-01-31 23:59:00|        0|             0|    []|CAN|51.2538| -85.3232|Canada|         Ontario|2025-12-30 21:21:23|covid/Canada/raw/...|2026-01-01 18:56:...|2026-01-01 18:57:...|\n",
      "|     1|          0|        1|             0|2020-01-31|     0|          0|          0.0|2020-01-31 23:59:00|        0|             0|    []|CAN|53.7267|-127.6476|Canada|British Columbia|2025-12-30 21:21:23|covid/Canada/raw/...|2026-01-01 18:56:...|2026-01-01 18:57:...|\n",
      "+------+-----------+---------+--------------+----------+------+-----------+-------------+-------------------+---------+--------------+------+---+-------+---------+------+----------------+-------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('delta').load(curated_aws_path)\n",
    "\n",
    "df.filter(col('created_ts')!=col('updated_ts')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
